---
title: "Analysis_Notebookv2"
author: "Cary"
date: "3/25/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

knitr::opts_chunk$set(
    fig.path = "D:/Documents/R/Digital Divide/Open_Data_Challenge/Analysis/Fig")
```

```{r Set up directory, include=FALSE}
setwd("D:/Documents/R/Digital Divide/Open_Data_Challenge/Analysis")
```

```{r Configuration on how many digital to print}
#This configuration ensure the report rounds the digital values 
#https://www.jason-french.com/blog/2014/04/25/formatting-sweave-and-knitr-output-for-2-digits/
library(knitr)
knit_hooks$get("inline")

inline_hook <- function (x) {
  if (is.numeric(x)) {
    # ifelse does a vectorized comparison
    # If integer, print without decimal; otherwise print three places
    res <- ifelse(x == round(x),
      sprintf("%d", x),
      sprintf("%.3f", x)
    )
    paste(res, collapse = ", ")
  }
}

knit_hooks$set(inline = inline_hook)
```

```{r Load packages}
library(tidyverse)
library(dplyr)
library(ggplot2)
library(janitor)
library(psych)
library(psychTools)
```
#Load data and transform before analysis 

```{r}
data <- read.csv("data.csv", header = T)
```

```{r}
hist(data$Percent_access_FCC, xlab = "Broadband Access Percentages", main = "Percent access at the county level (n = 3138)")
```

```{r}
hist(data$Avg_percent_access)
```

```{r}
hist(data$Percent_usage, xlab = "Broadband Usage Percentage", main = "Percent usage at the county level (n = 3138)")
```
```{r}
hist(data$Medi_Mbps, xlab = "Mbps", main = "Median speed by M-lab per County (n = 3138)")
```
```{r}
hist(data$Medi_fast_Mbps)
```
```{r}
hist(data$Avg_month_price)
```
```{r}
hist(data$Rurality)
```
```{r}
hist(data$Percent_PC_H)
```
```{r}
hist(data$Percent_Int_PC)
```

```{r}
colnames(data)
```

```{r}
#Select the columns we need,drop columns by index 
#We are dropping Avg_percent_access since Percent_access_Fcc is a better measure 
#Remove Has_PC, Has_PC_Int, Has_PC_only, and No_PC since we have the percentages columns 
data1 <- data[-c(23, 30:33)]
```

---------------------------------------------------------------------------
# Part 1. Statistical Analysis 

## 1.1 Descriptive Statistics 

```{r}
colnames(data1)
```

```{r}
#Turn COUNTY.ID to factors
data1$COUNTY.ID <- as.factor(as.character(data1[,1]))
#Turn ST to factors 
data1$ST <-as.factor(data1$ST)
```

```{r eval=FALSE, include=FALSE}
#Export data1 as csv
#write.csv(data1, file="data1.csv", quote=F, na="na", row.names=FALSE)
```

1.2 Distribution of numerical values 
```{r}
#Box and Whisker Plot
boxplot(data1[,-c(1,2,18)], boxwex = 0.2, las = 1)
#las() makes the x-labels horizontal (1), verical (2)
```

```{r}
#Box and Whisker Plot of selected variables
boxplot(data1[,c(7,8,9,10)], boxwex = 0.2, las = 1)
```
##Histogram of City

```{r}
hist(data$City)
```
## Histogram of Suburban 
```{r}
hist(data$Suburb)
```


```{r}
#Box and Whisker Plot of selected variables
par(mar=c(5,3,1,1)) #Adjust margin with par() to make x labels fit 
boxplot(data1[,c(11:17)], boxwex = 0.2, las = 1)
```
```{r}
#Box and Whisker Plot of selected variables
par(mar=c(5,3,3,1), +.1) #Adjust margin with par() to make x labels fit 
#mar() adjust bottom, left, top right
boxplot(data1[,c(19,20)], boxwex = 0.2, las = 1, main = "Distribution of Median Speed per county (n = 3138)") #las turn labels to vertical 
```
```{r}
#data1 <- read.csv("data_imputed.csv", header = T)
#groupby values 
use_state <- data1 %>% group_by(ST) %>% summarize (Usage = mean(Percent_usage))
```

```{r}
par(mar = c(2,4,2,0) +.1)
barplot(height = use_state$Usage,
        names = use_state$ST,
        space = 0.6,
        ylab = "Percentage",
        main = "Percent of Broadband Usage by Population per State (2019)",
        ylim = c(0, 0.8),
        las = 2,
        cex.names = 0.7)
```
```{r}

```







```{r}
#Box and Whisker Plot of selected variables
par(mar=c(5,3,0,1)) #Adjust margin with par() to make x labels fit 
#mar() adjust bottom, left, top right
boxplot(data1[,c(24,25)], boxwex = 0.2, las = 1) 
#las turn labels to vertical 
```
```{r}
#Box and Whisker Plot of selected variables
#par(mar=c(10,3,0,0)) #Adjust margin with par() to make x labels fit 
#mar() adjust bottom, left, top, right
boxplot(data1$Avg_month_price, horizontal = TRUE, ylab = "Avg_Month_Price") #las turn labels to vertical 
```


```{r eval=FALSE, include=FALSE}
des_table <- describe(data1)
des_table
write.csv(des_table,"D:/Documents/R/Digital Divide/Open_Data_Challenge/Analysis/dec_table.csv", row.names = F)
```


#----------------------TO DO ----------------------------------------------------
### Most Populated regions with K-12 students enrollment
## Break down geographical information by regions for better descriptive

### Percenage of homes with K-12 students and their access to internet + SEDA

## Append an estimated final cost column to the broadband dataset for each county 
### est_final_price
[The Cost of Connectivity Report](https://www.newamerica.org/oti/reports/cost-connectivity-2020/)suggests an average basic monthly cost of $68.36 for the cities, with $62.17 for promotional pricing and $83.41 regular pricing. Check the range of prices from the broadband dataset. 

[The Cost of Connectivity Report for Rural Area](https://www.google.com/url?q=https://www.newamerica.org/oti/reports/cost-connectivity-2020/&sa=D&source=editors&ust=1616209955787000&usg=AFQjCNHFDSBxivsvU44hETbKRpeyPneifw) (page 9) Average download speed in WV rural area is 25.65 Mbps, avg upload is 3.39 Mbps. (page 6) reported cost is advertised costs for new customer that would pay but not the actual price. (page 7) Median monthly cost is $84.99 for non-promotional pricing without equipment rental, speed surcharge, modem, and other fees. 
#---------------------------------------------------------------------------------

## 1.2 Correlation Analysis
### Overall selected variables 
```{r}
#drop the factor and character column before running correction
subset <- data1[-c(1, 2, 18)]
```

```{r}
#Obtain a pairwise correlation matrix for the entire dataset excluding factors level 
subset_corr <-corr.test(x = subset)
```

```{r}
#cor(subset, method = "pearson", use = "complete")
```

#-------------------------To do -----------------------------------
Data Mashups in R where factors level is use to display variable distribution 
- title 1 status, state level, and rurality
```{r}
#library(lattice)
#library(latticeExtra)
```
Corrrelation table - data mashup in R Fig 2-4
Scatterplots if needed 

#--------------------------------------


```{r}
library(corrplot)
```

### Urbanicity/Rurality with Broadband Access and Usage 

```{r}
cortable <- cor(subset, use = "complete.obs", method = c("pearson"))
corrplot(cortable, method = "number", type = "upper", number.cex = 0.7, tl.cex = 0.7)
```
```{r}
#Produce a image file of the correction table
png(height=1200, width=1500, pointsize=15, filename = "correlation.png")
corrplot(cortable, method = "color", addCoef.col="black")
```
[corrplot package](https://cran.r-project.org/web/packages/corrplot/vignettes/corrplot-intro.html)

## Correlation with p-values
```{r}
library(Hmisc)#produces correlation matrices with p-values
library(ppcor)#assess partial correlations
```
https://uc-r.github.io/correlations 
First-order partial correlation. We can do this by applying the pcor.test() function to assess the partial correlation between two specific variables controlling for a third
```{r}
#cor.test() gives confidence internals 
cor.test(subset)
```


```{r}
#rcorr() gives p-values 
rcorr(as.matrix(subset))
```

###------
No. of schools, Titile 1 status in the region and FCC availability 
```{r}
data_2 <- data[, c("COUNTY.ID", "Num_of_school","Total_enrollment", "City", 
               "Suburb", "Town", "Rural", "Rurality", "TAE_No", "TAE", "SW_TAE",
               "SW_No", "SW", "NOT_TitleI", "Unknown", "Percent_access_FCC",
               "Percent_usage", "Avg_percent_access", "Medi_Mbps", 
               "Medi_fast_Mbps", "Percent_PC_H", "Percent_Int_PC")]
```
For Title I status, there are different categories. 
[Title I allocation at the federal level](https://nces.ed.gov/blogs/nces/post/a-look-at-how-title-i-funds-are-allocated-in-the-u-s) 
```{r}
#For this part of the analysis, we aggregate the title 1 status into one variable.
data_2 <- transform(data_2, Title_I = (1 - NOT_TitleI))
```

```{r}
#Remove the un-needed columns in data_2
colnames(data_2)

data_3 = subset(data_2, select = -c(9:13, 15))
```

```{r}
colnames(data_3)
```

```{r eval=FALSE, include=FALSE}
cortable3 <- cor(data_3, use = "complete.obs", method = c("spearman"))
corrplot(cortable3, method = "color", addCoef.col="grey", type = "upper", number.cex = 0.7, tl.cex = 0.7) 
```
Format tabular data with formattable package (p.28 R Statistics Book)
```{r}
library(expss)
library(formattable)
```
[Data Viz Color Scheme](https://www.datanovia.com/en/blog/top-r-color-palettes-to-know-for-great-data-visualization/)
```{r}
library(RColorBrewer)
display.brewer.all()
```
```{r}
#t5 <- with(data_3, table(COUNTY.ID, Percent_usage))
#this method spreads out the count of each percent_usage for each county. 
t5 <- select(data_3, COUNTY.ID, Title_I, Rurality, Percent_usage, Medi_Mbps, Percent_PC_H, Percent_Int_PC)
t5
```
```{r}
#Rounding values to 2 decimal places
t5<- round(t5, digits = 2)
```


```{r}
#Setup color first 
col1 <- brewer.pal(n = 5, name = "Reds" ) #Sequential color 
display.brewer.pal(n = 5, name = "Reds")

#apply formatting 
formattable(t5, align = c("l", rep("r", NCOL(t5)-1,
                                    list("Title_I" = color_bar(col1)))))
              
#https://www.displayr.com/formattable/        
```
```{r}
cor(t5, use = "complete.obs")
#Correlation reflects the increase in percentage of title 1 schools within a county, their usage and speed is inverse. 
```
#-------------------------

### No. of computer and internet access at household by SEDA scores
SEDA scores are divided by grade and subject. Therefore, the 

#-----------seda -------------------
## Load SEDA dataset
### SEDA scores by county, grade, subject
```{r}
seda_score <-read.csv("seda_scores.csv", header = T)
```

```{r}
colnames(seda_score)
```
fips: State FIPS code
sedacounty: FIPS County Code
cs_mn_all: County grade-year-subject (gyb) Ach Mean, All Students, Cohort Scale (CS)
cs_mn_all: County grade-year-subject (gyb) Standard Error (SE) of Ach Mean, All Students, Cohort Scale (CS)
totgyb_all: Sample size of all estimates (number of tests in grade-year-subject)
```{r}
head(seda_score)
```
Note: Estimates in this scale are comparable across the whole country and over time, but not across grades or subjects.  See the technical documentation, and Reardon, Kalogrides, and Ho (2019), for details.

Note. CS version of the SEDA data is for research purposes, in which one unit in SD in student proficienty level in each grade referenced to NAEP average. 

```{r}
#Kernel Density Plot of Math, 3rd grade 

a <- density(seda_score$cs_mn_all, na.rm = T, kernel = c("gaussian"))
plot(a, main = "Density plot of all scores in cs_mn_all")
```
#### Subset data as "b" in tibble
```{r}
#take the needed columns 
b <- seda_score %>%
  group_by(sedacounty, subject, grade) %>%
  summarise(score = sum(cs_mn_all))
b
  
```
#### Spread the tibble 
```{r}
#Spread the data by grade level to subjects 
b_wide <- b %>% 
  spread(subject, score)
b_wide
```
https://datascienceplus.com/converting-data-from-long-to-wide-and-from-wide-to-long-simplified-tidyverse-package/

### Covariates
```{r}
seda_cov <-read.csv("seda_covariates.csv", header = T)
```

```{r}
colnames(seda_cov)
```
```{r}
head(seda_cov)
```
#### Subset columns 
sedacounty: SEDA County ID (2018)
grade: grade level from 3-8
perind: percent native americans in the grade
perasn:	percent asians in the grade
perhsp:	percent hispanics in the grade
perblk:	percent blacks in the grade
perwht:	percent whites in the grade
perfl:	percent free lunch in the grade
perrl:	percent reduced lunch in the grade
perfrl:	percent free or reduced lunch in the grade
perecd:	percent economically disadvantaged in the grade
perell:	% of all Students in County that are ELL (not available)
perspeced:	% of all Students in County that are Special Ed (not available)
hsflnfl: the information theory index is computed as the average deviation of each student's school racial diversity from the district-wide racial diversity. Values of 0 indicate no segregation while values of 1 indicate complete segregation. See Theil (1972) for more 
hsecdnec:the information theory index is computed as the average deviation of each student's school racial diversity from the district-wide racial diversity. Values of 0 indicate no segregation while values of 1 indicate complete segregation. See Theil (1972) for more 
sesall: ses composite, eb estimate, all families, time-varying 

Note: % schools in county that are located in urban, suburban, town, and rural are already in the school dataset. 

```{r}
cov <- select(seda_cov, c("sedacounty","grade","perind","perasn","perhsp",
                          "perblk","perwht","perfl","perrl","perfrl","perecd",
                          "hsflnfl","hsecdnec","sesall"))
```

```{r}
colnames(cov)
```

```{r}
head(cov)
```
### Combine scores and covariates dataframe
```{r}
seda_combo <- left_join(b_wide, cov, by = c("sedacounty", "grade"))
```


```{r}
anti_join(b_wide, cov, by = "sedacounty")
#The county ID 46102 was not present in the seda covariate dataset 
```
#------------------------------------------------------------------

## 1.3 Imputation
#### Missing Values
```{r}
#Currently there are 38 incomplete cases, the missing values are Percent_access_FCC (32 out of 38), Percent_usage (8 out of 38), the census information for those counties in VA (6 out 38). 
data1[!complete.cases(data1),] 
```

#### Imputation 
```{r}
#Address missing values
library(missRanger)
```
[missRanger](https://github.com/mayer79/missRanger)  
```{r}
data_imputed <-missRanger(data1, pmm.k = 50, num.trees = 1000)
```

```{r eval=FALSE, include=FALSE}
#Export the dataframe for record
#write.csv(data_imputed,"D:/Documents/R/Digital Divide/Open_Data_Challenge/Analysis/data_imputed.csv", row.names = F)
```

## Factor Analysis
https://www.geo.fu-berlin.de/en/v/soga/Geodata-analysis/factor-analysis/A-simple-example-of-FA/index.html

```{r}
#Create a composite indicator 
comp <- mlmdata[,c(19:22, 29:30)]
```


```{r}
#Principal Axis Factor Analysis with base R stats package 
model <- factanal(comp, factors = 1)
```

```{r}
model
```
```{r}
#Principal Axis Factor Analysis with base R stats package 
model <- factanal(comp[,-c(3,4)], factors = 1, scores = 'regression')
#have to indicate scores = regression to get factor scores 
```

```{r}
model
```

Extract Factor Score
http://bayes.acs.unt.edu:8083/BayesContent/class/Jon/R_SC/Module4/CompositeIndicators.R 
```{r}
#convert to vector and use summary, other wise you get a long list of scores 
summary(as.vector(model$scores))
```

```{r}
apply(model$loadings^2,1,sum)
```

```{r eval=FALSE, include=FALSE}
mlmdata_none <- factanal(mlmdata[, c(19:25)], factors = 2, rotation = "none")
mlmdata_varimax <- factanal(mlmdata[, c(19:25)], factors = 2, rotation = "varimax")
mlmdata_promax <- factanal(mlmdata[, c(19:25)], factors = 2, rotation = "promax")

par(mfrow = c(1,3))
plot(mlmdata_none$loadings[,1], 
     mlmdata_none$loadings[,2],
     xlab = "Factor 1", 
     ylab = "Factor 2", 
     ylim = c(-1,1),
     xlim = c(-1,1),
     main = "No rotation")
abline(h = 0, v = 0)

plot(mlmdata_varimax$loadings[,1], 
     mlmdata_varimax$loadings[,2],
     xlab = "Factor 1", 
     ylab = "Factor 2", 
     ylim = c(-1,1),
     xlim = c(-1,1),
     main = "Varimax rotation")

text(mlmdata_varimax$loadings[,1]-0.08, 
     mlmdata_varimax$loadings[,2]+0.08,
      colnames(mlmdata[, c(19:25)]),
      col="blue")
abline(h = 0, v = 0)

plot(mlmdata_promax$loadings[,1], 
     mlmdata_promax$loadings[,2],
     xlab = "Factor 1", 
     ylab = "Factor 2",
     ylim = c(-1,1),
     xlim = c(-1,1),
     main = "Promax rotation")
abline(h = 0, v = 0)
```

```{r}
library(radiant)
#weighted.sd (x, wt, na.rm = TRUE)
#Number of vector, number of weghts()
```



```{r}
# This rescaling function simply puts the scores back into the metric of the
# original questions (Keep in mind, some of the final scores may be slightly
# below '1' and some slightly above '4'; this results because we modeled the
# latent 'true scores'.

re.scale <- function(f.scores, raw.data, loadings){
  fz.scores <- (f.scores + mean(f.scores))/(sd(f.scores))
  means <- apply(raw.data, 1, weighted.mean, w = loadings)
  sds <- apply(raw.data, 1, weighted.sd, w = loadings)
  grand.mean <- mean(means)
  grand.sd <- mean(sds)
  final.scores <- ((fz.scores * grand.sd) + grand.mean)
  return(final.scores)
  }

```

```{r}
#raw data
df <- comp[,-c(3,4)]
#Assigned factor scores to a variable
model_score <- as.vector(model$scores)
#Assigned model loading to a variable
model_loadings <- abs(model$loadings[,1])

model_final_score <- re.scale(model_score, df, model_loadings)
summary(model_final_score)
```
http://bayes.acs.unt.edu:8083/BayesContent/class/Jon/R_SC/Module4/CompositeIndicators.R

```{r}
get.scores.fun <- function(data){
  fact <- factanal(data, factors = 1, scores = "regression")
  f.scores <- fact$scores[,1]
  f.loads <- fact$loadings[,1]
  rescaled.scores <- re.scale(f.scores, data, f.loads)
  output.list <- list(rescaled.scores, f.loads)
  names(output.list) <- c("rescaled.scores","factor.loadings")
  return(output.list)
  }
```

```{r}
b <- get.scores.fun(df)
```



##1.4 Multilevel modeling

```{r}
mlmdata <- read.csv("data_imputed.csv", header = T)
```

```{r}
library(nlme)
```

### null model in MLM



```{r}
#Use VarCorr fucntion to obtain variances
VarCorr(null)
```

```{r}
intervals(null, which = "fixed")
```

```{r}
library(misty)
```

```{r}
multilevel.icc(mlmdata$Percent_usage, group = mlmdata$COUNTY.ID)
```






### PCA
https://www.kaggle.com/agailloty/comprehensive-pca-with-r-using-factominer
```{r}
library(FactoMineR)
```

```{r}
colnames(data_imputed)
```




## 5.3 Regression Analysis
### Access level Composite Indicator 
We conceptualize access level for K-12 students in the context of physical access (which includes internet access and technology in a form of PC). 

First level of digital divide - Internet connection (van Deursen & van Dijk, 2019)
 - subcomponents of first level is material access in which beside internet connection, there are computer devices, software subscription, and peripheral equipment. Material access can be distinguished as device opportunity (substitution between PC, smartphone or tablet), device and peripheral diversity (number of devices), and maintenance expenses (level of subscription and cost). 

Second level of digital divide - Internet skills and usage 
Third level of digital divide - Tangible benefits of internet use 

```{r}
#Load the Dataframe of School information first 
head(data)
```

```{r}
colnames(data)
```


```{r}
# Store the PCA result in an object valled data_pca
# quali.sup is to choose variables that gives context in the data and not meant for PCA 
data_pca <- PCA(data_imputed, quali.sup = c(1, 2, 18), graph = T)
```

```{r}
summary(data_pca)
```

```{r}
data_pca$eig
```


```{r}
#Plot the variable factor map
plot.PCA(data_pca, axes = c(1,2), choix = "var") +
  theme(panel.grid.major = element_blank(),
        plot.title =element_text(size=14, color="blue"),
        axis.title = element_text(size=12, color="red")) 
#Dim 1 is correlation by Pearson r

```

```{r}
data_pca$var
```
```{r}
#Contribution of each variable on the dimensions
data_pca$var$contrib
```



```{r}
library(factoextra)
```
http://www.sthda.com/english/articles/31-principal-component-methods-in-r-practical-guide/118-principal-component-analysis-in-r-prcomp-vs-princomp/


```{r}
fviz_screeplot(data_pca, addlabels = TRUE, ylim = c(0, 50))
```
```{r}
fviz_pca_ind(data_pca,
             col.ind = "cos2", # Color by the quality of representation
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE     # Avoid text overlapping
             )
```

```{r}
# Extract the results for variables
var <- get_pca_var(data_pca)
```

```{r}
# Contributions of variables to PC1
fviz_contrib(data_pca, choice = "var", axes = 1, top = 10)
```

```{r}
# Contributions of variables to PC2
fviz_contrib(data_pca, choice = "var", axes = 2, top = 10)
```

```{r}
# Control variable colors using their contributions to the principle axis
fviz_pca_var(data_pca, col.var="contrib",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE # Avoid text overlapping
) + theme_minimal() + ggtitle("Variables - PCA")
```

Purdue Digital Divide Index
https://storymaps.arcgis.com/stories/8ad45c48ba5c43d8ad36240ff0ea0dc7

The INFA score groups five variables related to broadband infrastructure and adoption: (1) percentage of total 2018 population without access to fixed broadband of at least 100 Mbps download and 20 Mbps upload as of December 2019; (2) percent of homes without a computing device (desktops, laptops, smartphones, tablets, etc.); (3) percent of homes with no internet access (have no internet subscription, including cellular data plans or dial-up); (4) median maximum advertised download speeds; and (5) median maximum advertised upload speeds.

The SE score groups five variables known to impact technology adoption: (1) percent population ages 65 and over; (2) percent population 25 and over with less than high school; (3) individual poverty rate; (4) percent of noninstitutionalized civilian population with a disability: and (5) a brand new digital inequality or internet income ratio measure (IIR). In other words, these variables indirectly measure adoption since they are potential predictors of lagging technology adoption or reinforcing existing inequalities that also affect adoption.

Because these variables have different units and normal distributions, z-scores were calculated for each variable and geography. Z-scores standardize the data and indicate where a particular observation falls compared to the mean and standard deviation of the sample. Please note that these scores were calculated by looking at the geographic units (Census tracts, counties) and comparing them with their peers. For this reason, scores are not comparable across different geography tiers (Census tract versus counties versus states).

ince the DDI was designed to show a larger digital divide as the score increases, careful attention was paid to the signs in equations 1 and 2. The rationale behind the infrastructure/adoption (INFA) score (equation 1) was: as the z-scores of the percent of population without fixed 100/20 (NBBND), no internet access (NIA), and no computing devices (NCD) increases (+), the divide increases; while the z-scores of the median download (DNS) and upload (UPS) speeds increase, the digital divide decreases (-).

A similar rationale was used to calculate the socioeconomic score (SE) in equation 2: as the z-scores of the percent population ages 65 and over (AGE65) increases (+), so does the potential lag in technology adoption; same as the z-scores of individual poverty rate (POV) increases (+), percent population 25 and over without a high school degree (LTHS) increases (+), and percent noninstutionalized population with any disability (DIS) increases (+), so does the digital divide.

Equation 1: INFA = NBBND*0.3 + NIA*0.3 + NCD*0.3 – DNS*0.05 – UPS*0.05
Equation 2: SE = AGE65 + POV + LTHS + DIS

Notice however that the SE components are given equal weight while INFA components are not. This may result in more variance in the SE score compared to the INFA score. This in turn gives SE more influence on the DDI score compared to the INFA score. For this reason, z-scores of the INFA and SE scores were calculated and then added up to calculate the final DDI score giving both components equal influence as shown in equation 3.

Equation 3: DDI = INFA + SE

#### Percent usage for household with children
```{r}
#Rename the dataset
imp_data <- data_imputed
```

```{r}
#Percent of family that have children within each county
imp_data$Percent_Fm <- imp_data$Home_w_student/imp_data$Num_Household
```

```{r}
#Percent of usage is from household with children
imp_data$Percent_stu_usage <- imp_data$Percent_usage*imp_data$Percent_Fm
```

##### Access level is made up of % computer and internet at home per household (as a physical acess) + quality of broadband (infrastructure, 25/3 Mbps, lowest fixed broadband in DDI) + Opportunity (by provider) and then compare to Actual Usage (by Microsoft)

##### Adding demographic information to this measure and then do a group comparison on this measure to detemine access by group. Then we can also use the access level in comparison with relative diversity index to see if there is any correlation. 

## Multilevel Modeling 
How does broadband access and use varies across schools with different Title 1 status? 

## Spatial Analysis 