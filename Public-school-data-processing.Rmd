---
title: "Public School Data Processing"
author: "Cary K. Jim"
date: "3/13/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.path = "D:/Documents/R/Open_data_challenge/Figure")
```

```{r}
getOption("digits")
```

This configuration ensure the values are rounded in the output report The codes are referenced from: <https://www.jason-french.com/blog/2014/04/25/formatting-sweave-and-knitr-output-for-2-digits/>

```{r Configuration digits}
library(knitr)
knit_hooks$get("inline")

inline_hook <- function (x) {
  if (is.numeric(x)) {
    # ifelse does a vectorized comparison
    # If integer, print without decimal; otherwise print three places
    res <- ifelse(x == round(x),
      sprintf("%d", x),
      sprintf("%.3f", x)
    )
    paste(res, collapse = ", ")
  }
}

knit_hooks$set(inline = inline_hook)
```

```{r Load packages}
library(tidyverse)
library(dplyr)
library(ggplot2)
library(readr)
library(stringr)
library(janitor)
library(psych)
library(readxl)
library(psychTools)
```

The NCES Public Schools Characteristics Information was exported in March 2021. The web interface to extract a custom file is the NCES Elementary and Secondary Information System <https://nces.ed.gov/ccd/elsi/>

The following dataset is for the 2018-2019 school years.

```{r}
#Public school information exported from ELIS 2018-2018 school year used symbols "-" for missing values, † is for Not applicable, ‡ for data not met quality standard
public_school <-read.csv('public_schoolv3.csv', na.strings = c("","-","‡"), 
                         header = T, strip.white = T, sep = ",",
                         stringsAsFactors = TRUE, 
                         fileEncoding="UTF-8-BOM")

#public school file exported from ELIS, when importing the excel file it was problematic with mixed data types.
#Note that csv version is 26 MB, instead of 15 MB in excel format
```

```{r Column Names}
colnames(public_school)
```

```{r}
head(public_school)
```

```{r Data Types}
str(public_school) #99348 rows
```

Note that enorllment information : Members, Male, and Female are read-in as factors level. We will have to convert those later.

```{r}
#Check for duplicates
get_dupes(public_school)
```

## Part 1. Data Exploration

### Task 1:Determine how many incomplete cases

```{r}
public_school[!complete.cases(public_school),]
# There are 5049 incomplete cases in the public school data
```

```{r Types of schools in the dataset}
table(public_school$School.Type)
```

```{r}
#What falls in the alternative/other school category in School.Type?
public_school %>% filter(School.Type == "4-Alternative/other school")
```

```{r School status}
#Table of school status and counts
table((public_school$Updated.Status))
```

```{r}
#Do we have any information for school that is "Added" or "Future" status? 
public_school %>% filter(Updated.Status == "7-Future")
```

Any schools under the "7-Future" status do not have enrollment informaton.

```{r}
#Do we have any information for school that is "Added" or "Future" status? 
public_school %>% filter(Updated.Status == "4-Added")
```

Some added schools have information on enrollment and some schools do not.

```{r}
#Changed boundaries schools
public_school %>% filter(Updated.Status == "5-Changed Boundary/Agency")
```

We do have enrollment information for these schools that changed boundaries

```{r}
public_school %>% filter(Updated.Status == "8-Reopened")
```

Some values are missing in the reopened schools.

```{r}
#Do we have any information for school that is "New" 
public_school %>% filter(Updated.Status == "3-New")
```

```{r Agency types}
table(public_school$Agency.Type)
```

```{r}
public_school %>% filter(Agency.Type == "4-Regional Education Service Agency (RESA)")
```

Schools operates under the RESA district type seems to have missing enrollment information. \#------------------------------------------------------------------------------ Reviewing the data, it reveals some useful information. 1. For example, we are not including any public schools listing that provides adult education. However, the School name revealed that a portion of these incomplete cases are "ADULT ED" or "Adult education".

2.  The Updated.Status variables provides information on the operational status of the school. We cannot simply remove school by these categories because enrollment information are included in some categories. Only the "Future" status have no enrollment information.

3.  District Types which is named as Agency type provides information on who operates these schools. Generally, RESA are entities that support local school district and therefore may be serving students that is already counted in a regular school.

## Part 2.Data Cleaning and Processing

### Task 2.1 Remove schools that is not in operation or with no enrollment

```{r Remove by 0 enrollment }
# Remove schools that have no enrollment information, the subset function will also drop rows with no values
public_school <- subset(public_school, !(Members == "0"))  #97225 rows
```

```{r Remove by n/a enrollment}
#Remove schools that have no enrollment information, n/a is not applicable 
public_school <- subset(public_school, !(Members == "n/a")) #95267 rows
```

```{r}
#Check how the school status looks like after removing schools with no enrollment information
#Do we have any information for school that is "Added" or "Future" status? 
table(public_school$Updated.Status)
```

### Task 2.2 Remove schools based on Agency Type

```{r Remove by RESA agency}
# We will exclude Regional Education Service Agency (RESA)
public_school <- subset(public_school, !(Agency.Type == "4-Regional Education Service Agency (RESA)")) #94619 rows
```

```{r Review Agency.Type categories}
table(public_school$Agency.Type)
```

We don't want to simply drop a school if it is not a regular school. We are doing the best to include specialized schools that are serving students who may not be enrolled in a general education classroom.

\#\#\#Task 2.3 Review the incomplete cases at this point

```{r}
public_school[!complete.cases(public_school),] #3523 rows
#It looks like FTE is the column that is causing the incomplete cases at this time. 
```

There are still a subset of schools that contain missing values, such as "Title.I. School.Status", "FTE.Equivalent", and "Pupil.Teacher.Ratio". It won't be signifantly affect the following steps. So we will leave these missing values in the data for now.

### Task 3. Convert Data Types

```{r}
head(public_school)
```

#### Task 3.1

First, we have to deal with the enrollment information. Note: We have to pass the value as characters first, otherwise R will assign a level value

```{r Convert Memebers to numeric}
#Members, Male, Female, FTE and Pupil.Teacher Ratio are as a factor level due to the symbol used in the original data 
public_school$Members <- as.integer(as.character(public_school[,15]))
```

```{r Review dataframe after conversion}
head(public_school)
```

```{r Convert Male and Female counts to numeric}
public_school$Male <- as.integer(as.character(public_school[,16]))
public_school$Female <- as.integer(as.character(public_school[,17]))
```

```{r Review dataframe }
head(public_school)
```

\#\#\#\#Task 3.2 FTE and Pupil Teacher Ratio \#\#\#\#\# Convert FTE and Pupil Teacher Ratio to numeric

```{r Convert FTE to numeric}
public_school$FTE.Equivalent <- as.numeric(as.character(public_school[,18]))
```

```{r Convert Pupil to Teacher Ratio}
public_school$Pupil.Teacher.Ratio <- as.numeric(as.character(public_school[,19]))
```

Note that original n/a - not applicable values are now replaces with NAs, which is not a problem since we don't have information on that either.

```{r}
head(public_school)
```

#### Task 3.3 Review incomplete cases at this point

```{r}
public_school[!complete.cases(public_school),]
# There are about 3989 schools that didn't have the FTE information or Pupil to Teacher Ratio. However those are not necessary needed in the next step. We can move forward this this dataframe. 
```

### Task 4. Rename factor levels and re-order levels

#### Review Title 1 status categories

```{r}
levels(public_school$Title.I.School.Status)
```

```{r Counts in each Title 1 categories}
table(public_school$Title.I.School.Status)
```

#### Task 4.1 Re-organize levels

```{r Drop n/a level in Title 1 status, include=FALSE}
#Drop n/a as a level since there is no values 
public_school$Title.I.School.Status <-droplevels(public_school$Title.I.School.Status)
```

```{r View counts in each levels within Title 1}
table(public_school$Title.I.School.Status) 
#Total count is 93810, which means there are missing values in the dataset 
```

```{r Check for missing values in Title 1 status}
#Where are the missing values in Title 1 Status?
table(is.na(public_school$Title.I.School.Status)) #There are 809 missing value in Title 1 
```

```{r Create an unknown level }
#Create a level first in order to handle missing values, otherwise it gives an error
a <- levels(public_school$Title.I.School.Status)
a[length(a) + 1] <- "Unknown"
```

```{r Assign the unknown level }
#Add the level to the variables
public_school$Title.I.School.Status <- factor(public_school$Title.I.School.Status, levels = a)
#Add the level to the missing values 
public_school$Title.I.School.Status[is.na(public_school$Title.I.School.Status)] <- "Unknown" 
```

```{r}
#Review the table to see if the missing values are now assigned to "Unknown"
table(public_school$Title.I.School.Status)
```

#### Rename levels to shorted the category names

```{r Assign accroymns}
#Rename levels in Title 1 Status 
levels(public_school$Title.I.School.Status) <- c("TAE_No", "TAE", "SW_TAE", "SW_No", "SW", "NOT_TitleI", "Unknown")
```

```{r View levels again after change}
levels(public_school$Title.I.School.Status)
```

```{r Review levels and counts in each}
#Check to make sure the count for each level is still correct 
table(public_school$Title.I.School.Status)
```

\#\#\#Task 5 Aggregrate Urbanicity/Rurality information

```{r}
#View Counts in each level 
table((public_school$Urban.centric.Locale))
```

```{r View levels in Locale}
#Rename the Urban.centric.Locale information 
levels(public_school$Urban.centric.Locale)
```

```{r Aggregate City level}
#For this analysis, we will only be concern with the 4 major levels of locale 
levels(public_school$Urban.centric.Locale)[1:3]<- "City"
levels(public_school$Urban.centric.Locale)
```

```{r Aggregate Suburban level }
#I discovered that the levels changed after converting city.So I need to adjust the index
levels(public_school$Urban.centric.Locale)[2:4]<- "Suburb"
levels(public_school$Urban.centric.Locale)
```

```{r Aggregate Town level }
levels(public_school$Urban.centric.Locale)[3:5]<- "Town"
levels(public_school$Urban.centric.Locale)
```

```{r Aggregate Rural level}
levels(public_school$Urban.centric.Locale)[4:6]<- "Rural"
levels(public_school$Urban.centric.Locale)
```

```{r Check to ensure levels have the correct counts}
table(public_school$Urban.centric.Locale)
```

Urbanicity/Rurality is converted to 4 levels now

```{r eval=FALSE, include=FALSE}
#Export the cleaned data 
#write.csv(public_school,"D:/Documents/R/Digital Divide/Open_Data_Challenge/Analysis/cleaned_school.csv")
```

\#------------------------------------------------------------------------------- \# Part 3: Create two aggreage version of the dataset \#\# State Level

```{r}
#read.csv('cleaned_school.csv', header = T)
```

```{r Number of School by State Table}
# A quick count of schools by each state in the processed data
table(public_school$ST)
```

```{r Number of School by Urbanicity/Rurality}
table(public_school$Urban.centric.Locale)
```

```{r Number of School by Titile I Status}
table(public_school$Title.I.School.Status)
```

### Task 1. Review categorical information by state

```{r Urbanicity/Rurality by State}
# Collapse the data by State and their locale 
public_school %>% 
  group_by(ST, Urban.centric.Locale) %>%
  summarize(locale = n())
```

Review the Title 1 information by state

```{r Title I School Status by State}
public_school %>% 
  group_by(ST, Title.I.School.Status) %>%
  summarize(each_count = n())
```

```{r}
public_school %>% 
  group_by(ST) %>%
  summarize(total_enrollment = sum(Members))
```

### Task 2. Create a new dataframe for state level information

Group selected variables by state level and calculate a percentage of that information or a total count

#### Total student enrollment and gender

```{r Aggregate enrollment info by State}
# Create a new dataframe with state level information 
schools_state <-
  public_school %>% 
  group_by(ST) %>%
  summarise(Num_of_school = n(), Total_enrollment = sum(Members), 
            male = sum(Male, na.rm = TRUE), Female = sum(Female, na.rm = TRUE))
```

Beware that some schools have missing values for one of the gender and the use of sum() of those return a NA value. So we have to use a different method by adding na.rm = True.

```{r}
schools_state
```

#### Task 2.1 Urbanicity/Rurality

```{r Show how many levels is present by State}
public_school %>% 
  group_by(ST) %>%
  summarise(Urbanicity = n_distinct(Urban.centric.Locale))
# This method gives me the count of categories, but not how many within the category 
```

```{r Create a dataframe for locale info}
t1 <- public_school %>% 
  group_by(ST, Urban.centric.Locale) %>%
  summarise(Locale_count = n())
t1
#Percentage calculation was hold off, when it is added by 
#mutate(Locale_percent = Locale_count/sum(Locale_count))
#it caused problem in using spread()
```

```{r Reshape dataframe to spread levels as column headings}
t1<- spread(t1, Urban.centric.Locale, Locale_count)
t1
```

Row 8: DC City 222\
DC Rural 1 Row 40: RI City 76\
RI Suburb 187\
RI Rural 24

```{r Fill-in missing values with 0}
#Row number 8 and row 40 in the t1 dataframe 
t1[8, 3] <- 0	
t1[8, 4] <- 0
t1[40, 4] <- 0

t1
```

```{r Total acorss locale levels}
#Create a total column
t1$total <- t1$City + t1$Suburb + t1$Town + t1$Rural
#Replace each locale by its own percentage 
#Create a list first to check if calculation are done correctly
t1$City <- t1$City/t1$total
```

```{r Replace each level values as percentages}
#Replace each locale by its own percentage 
t1$Suburb <- t1$Suburb/t1$total
t1$Town <- t1$Town/t1$total
t1$Rural <- t1$Rural/t1$total
t1
```

#### Task 2.2 Title I status

```{r Create a dataframe for Title I status levels}
t2 <- public_school %>% 
  group_by(ST, Title.I.School.Status) %>%
  summarise(each_count = n())
```

```{r}
t2
```

```{r eval=FALSE, include=FALSE}
# A different method with the same result as t2
#public_school %>% count(ST, Title.I.School.Status)
```

```{r Spread the columns}
t2 <- spread(t2, Title.I.School.Status, each_count)
t2
```

Since we have to perform calculation, we will impute all NA as zero

```{r Fill-in missing counts as 0}
t2[is.na(t2)] = 0
```

```{r Total across the levels}
#Create a total column
t2$total <- rowSums(t2[,2:8])
t2
```

```{r Calculate percentage of each levels by total}
t2$Unknown <- t2$Unknown/t2$total
t2$TAE_No <- t2$TAE_No/t2$total
t2$TAE <- t2$TAE/t2$total
t2$SW_TAE <- t2$SW_TAE/t2$total
t2$SW_No <-t2$SW_No/t2$total
t2$SW <- t2$SW/t2$total
t2$NOT_TitleI <- t2$NOT_TitleI/t2$total
```

```{r View the result table }
t2
```

```{r Verify the calculation}
#Confirming the percentages are calculated correctly
public_school %>% 
  group_by(ST, Title.I.School.Status) %>%
  summarise(each_count = n()) %>%
  mutate(Title1_percent = each_count/sum(each_count))
```

\#\#Task 3. Combine dataframes at the state level \#\#\# Merge schools_state with urbanciity/rurality table

```{r}
schools_state <- left_join(schools_state, t1, by = "ST")
```

```{r}
head(schools_state)
```

```{r}
#We can drop the total count for urbanicity/rurality -column index 10
schools_state <- schools_state[-c(10)]
```

### Merge schools_state with Title 1 info

```{r}
#Append the title 1 information by each state 
schools_state <- left_join(schools_state, t2, by = "ST")
```

```{r}
head(schools_state)
```

```{r drop total column (duplicated count)}
#Again, drop the total count column , index 17
schools_state <- schools_state[-c(17)]
```

```{r}
head(schools_state)
```

```{r eval=FALSE, include=FALSE}
#Export the dataframe for record
#write.csv(schools_state,"D:/Documents/R/Digital Divide/Open_Data_Challenge/Analysis/schools_by_state.csv")
```

\#\#County level

### Task 1. Create a new dataframe with county level information

```{r Dataframe for County Level information}
schools_county <-
  public_school %>% 
  group_by(COUNTY.ID, County_Name) %>%
  summarise(Num_of_school = n(), Total_enrollment = sum(Members), 
            Male = sum(Male, na.rm = TRUE), Female = sum(Female, na.rm = TRUE))
```

County dataframe has to be group by ID and County Name, otherwise it caused issue with counting the right combination of county and schools.

```{r}
schools_county
```

### Task 2. Assign a new dataframe to store Urbanicity/Rurality info by county level

```{r Create dataframe for each county with locale info}
t3 <- public_school %>% 
  group_by(COUNTY.ID, County_Name, Urban.centric.Locale) %>%
  summarise(Locale_count = n())
t3
```

As you see some county may have more than one type of geogrphical categories.

```{r Reshape the table with levels as columns}
t3<- spread(t3, Urban.centric.Locale, Locale_count)
t3
```

```{r Fill in missing values with 0}
#Fill in zero for NA columns after spreading 
t3[is.na(t3)] = 0
head(t3)
```

```{r Create a total column for locale}
#Create a total column
t3$locale_total <- t3$City + t3$Suburb + t3$Town + t3$Rural
```

```{r Calculate percentage for each column}
t3$City <- t3$City/t3$locale_total
t3$Suburb <- t3$Suburb/t3$locale_total
t3$Town <- t3$Town/t3$locale_total
t3$Rural <- t3$Rural/t3$locale_total

head(t3)
```

```{r Review percentage calculations}
public_school %>% 
  group_by(COUNTY.ID, County_Name, Urban.centric.Locale) %>%
  summarise(Locale_count = n()) %>%
  mutate(Locale_percent = Locale_count/sum(Locale_count))
```

### Task 3. Title I Status

```{r Collapse Title I Status by County }
t4 <- public_school %>% 
  group_by(COUNTY.ID, County_Name, Title.I.School.Status) %>%
  summarise(each_count = n())
```

```{r}
head(t4)
```

```{r Reshape dataframe}
t4 <- spread(t4, Title.I.School.Status, each_count)
t4
```

```{r Fill on missing values with 0}
t4[is.na(t4)] = 0
```

```{r Create a total column}
t4$status_total <- rowSums(t4[,3:9])
t4
```

```{r Calculate percentages of each level }
t4$Unknown <- t4$Unknown/t4$status_total
t4$TAE_No <- t4$TAE_No/t4$status_total
t4$TAE <- t4$TAE/t4$status_total
t4$SW_TAE <- t4$SW_TAE/t4$status_total
t4$SW_No <-t4$SW_No/t4$status_total
t4$SW <- t4$SW/t4$status_total
t4$NOT_TitleI <- t4$NOT_TitleI/t4$status_total
```

```{r View result}
head(t4)
```

Confirming the percentages are calculated correctly

```{r Verifty the calculation}
public_school %>% 
  group_by(COUNTY.ID, Title.I.School.Status) %>%
  summarise(each_count = n()) %>%
  mutate(Title1_percent = each_count/sum(each_count))
```

I randomly checked one of the county "01019" (leading zero got removed) which is Cherokee in AL. There are currently 8 schools serving all the students in that area. We excluded the Regional Education Center from all the listing. Checking the raw data, there is no enrollment information for the vocational school excluded. So therefore, enrollment is not skewed by excluding this school site.

### Task 4. Merge dataframes for County Level

```{r Left Join with urbanicity/rurality}
schools_county <-left_join(schools_county, t3, by = "COUNTY.ID")
```

```{r}
head(schools_county)
```

```{r Drop total column (duplicated)}
schools_county <- schools_county[-c(12)]
```

### Merge schools_state with Title 1 info

```{r Merge title 1 by county info}
#Append the title 1 information by each state 
schools_county <- left_join(schools_county, t4, by = "COUNTY.ID")
```

```{r}
head(schools_county)
```

```{r drop total column (duplicated)}
schools_county <- schools_county[-c(20)]
```

```{r}
head(schools_county)
```

```{r Drop duplicated county name}
#Because of the group_by of COUNTY ID and Name, there are duplicated name columns to be removed. 
colnames(schools_county)
schools_county <- schools_county[-c(7,12)]
```

```{r Rename County_Name column to remove x}
colnames(schools_county)[2] <- "County_Name"
```

```{r}
head(schools_county)
```

```{r eval=FALSE, include=FALSE}
#Export the dataframe for record
#write.csv(schools_county,"D:/Documents/R/Digital Divide/Open_Data_Challenge/Analysis/schools_by_county.csv")
```

\#--------------------------------------------------------------------------------- \# Part 4. Combine broadband information with school data for investigation \#\# Load Microsoft Broadband usage data at the County Level

```{r}
# Broadband Usage Estimates by County Level from Microsoft
microsoft <- 'https://raw.githubusercontent.com/microsoft/USBroadbandUsagePercentages/3cc660f1f54fd73274527a4a60ef870726abf2ba/dataset/broadband_data.csv'

usage_county <- read.csv(url(microsoft), header = T, sep = ",", 
                         strip.white = TRUE, fileEncoding="UTF-8-BOM")
```

```{r}
head(usage_county)
```

```{r eval=FALSE, include=FALSE}
#Export the dataframe for record
#write.csv(usage_county,"D:/Documents/R/Digital Divide/Open_Data_Challenge/Analysis/usage_county.csv")
```

## Rename columns names and data types

### Rename the column names

```{r}
#BROADBAND AVAILABILITY PER FCC: percent of people per county with access to fixed terrestrial broadband at speeds of 25 Mbps/3 Mbps as of the end of 2017 
colnames(usage_county)[4] <- "Percent_access_FCC"
```

```{r}
#BROADBAND USAGE: percent of people per county that use the internet at broadband speeds based on the methodology explained above. Data is from November 2019.
colnames(usage_county)[5] <- "Percent_usage"
```

### Convert to numeric

This conversion also force any of the existing field with "-" to NA

```{r}
usage_county$Percent_access_FCC <- as.numeric(usage_county[,4])
```

```{r}
usage_county$Percent_usage <- as.numeric(usage_county[,5])
```

```{r}
#Check for missing values in either of the column 
#There are 39 counties mostly without FCC Percentage of access information and 6 county without Broadband Usage information. 
usage_county[!complete.cases(usage_county),] 
```

We used Fixed Broadband Deployment Map to check these areas. Perry County in AL have three Satellite Providers and two of them are providing at 25/3 or more speed. [<https://broadbandmap.fcc.gov/#/location-summary?version=dec2019&place_name=Perry%20County,%20Alabama,%20United%20States&lat=32.635830&lon=-87.291940&tech=acfosw&speed=25_3&vlat=32.63550878159961&vlon=-87.28953899999999&vzoom=14.407357623888121>]

```{r}
#Check for duplicates
get_dupes(usage_county)
```

## Task 1. Combine school data with broadband usage information

```{r}
schools_county <- read.csv("schools_by_county.csv", header = T)
schools_county <- schools_county[-c(1)]
```

```{r}
#3138 rows
school_b_usage <- left_join(schools_county, usage_county, by = "COUNTY.ID")
```

```{r}
head(school_b_usage)
```

```{r}
colnames(school_b_usage)
```

```{r}
#Remove duplicated county name column
school_b_usage <- school_b_usage[-c(19)]
```

```{r}
#Rename state column
colnames(school_b_usage)[18] <- "ST"
```

```{r}
str(school_b_usage)
```

## Missing values

```{r}
#Check for missing values
sum(is.na(school_b_usage))
#There are 42 missing values 
```

```{r}
#Check missing values by columns
sum(is.na(school_b_usage$Percent_usage))
#There are 8 columns
```

```{r}
#There are 38 rows with missing values and most of them are in town or rural area. 
school_b_usage[!complete.cases(school_b_usage),] 
```

Notice that there are two counties that do not have a state information. Row 82, 2158, Kusilvak Census Area Row 2410, 46102, Oglala Lakota County

```{r}
#For now, I'm going to impute this information as if they don't have any available information.
school_b_usage[82,18] <- "AK"
school_b_usage[2410,18] <-"SD"
```

```{r eval=FALSE, include=FALSE}
#We don't have FCC information and the Broadband Now dataset don't have these two counties. So I used the Microsoft Zip level usage to estimate this two values. 
school_broadband_usage[82,20] <- 0.21
school_broadband_usage[2410,20] <- 0.27
```

```{r eval=FALSE, include=FALSE}
#Because we didn't have broadband info from FCC column. It remains NA. 
school_broadband_usage[!complete.cases(school_broadband_usage),] 
```

```{r}
describe(school_b_usage)
#After converting the two columns to numeric, there are more missing cases. 
```

```{r}
school_b_usage[!complete.cases(school_b_usage),] 
```

There are 6 county in VA do not have broadband usage data in the dataframe These are COUNTY.ID 51690 Martinsville city, 51685 Manassas Park city, 51678 Lexington city, 51600 Fairfax city, 51595 Covington city.

Therefore, I have to find other substitution for the broadband usage values for now. The census quick facts (v2019) table provide some population estimates that can be used. <https://www.census.gov/quickfacts/fact/table/highlandcountyvirginia,surrycountyvirginia,martinsvillecityvirginiacounty,manassasparkcityvirginiacounty,lexingtoncityvirginiacounty/PST045219>

51580 Covington City has about 77.2% households with broadband internet subscription 51595 Emporia City has about 65.2% households with broadband internet subscription 51600 Fairfax City has about 95.4% households with broadband internet subscription 51678 Lexington City has about 71.9% households with broadband internet subscription 51685 Manassas Park city has about 89.6% households with broadband internet subscription 51690 Martinsville city has about 73.9% households with broadband internet subscription

Using 51181 Surry County and 51091 Highland County as reference. Surry County estimated to have 64.8% of households with broadband internet subscription. Highland County has 76.5% of households with broadband internet subscription. We can assumed that other counties within those percentage is with 0.05 to 0.08. Counties that are about 80% in these rural area will be around 0.10.

```{r eval=FALSE, include=FALSE}
school_broadband_usage[2918,20] <- 0.08
school_broadband_usage[2920,20] <- 0.02
school_broadband_usage[2921,20] <- 0.10
school_broadband_usage[2929,20] <- 0.08
school_broadband_usage[2932,20] <- 0.10
school_broadband_usage[2933,20] <- 0.08
```

Now, these are the counties that do not have FCC Broadband Availability information by the end of 2017.

```{r}
#Confirm the data types have been updated 
sapply(school_b_usage, class)
```

```{r eval=FALSE, include=FALSE}
#Export the dataframe for record
#write.csv(school_b_usage,"D:/Documents/R/Digital Divide/Open_Data_Challenge/Analysis/school_broadband_usage.csv")
```

# Load the merged file of school info and microsoft county level broadband info

```{r}
#Load the merged file which has zipcode info from Microsoft files to account for missing zip codes within a county in the Broadband now data.  
sch_broadband <- read.csv("school_broadband_usage.csv", header = T)
sch_broadband <- sch_broadband[-c(1)]
```

## Task 3. Import the merged Census and Broadband_now data

```{r}
fcc_zip <-read.csv("broadband_combined.csv", header = T)
head(fcc_zip)
```

```{r}
str(fcc_zip)
```

### Recode data type

```{r}
fcc_zip$Month_price <- as.numeric(fcc_zip$Month_price)
```

```{r}
#Some of the numerical values in providers column will have to fill in with 0 for missing values. 
fcc_zip[is.na(fcc_zip)] = 0
#This method will address the average calculation of providers reported in the FCC data. We will assumed that zipcodes that doesn't have reported services have 0 providers. 
```

### Groupby the relevant variables by County Level

```{r}
a<-fcc_zip %>% 
  group_by(COUNTY.ID) %>% #There are 3136 rows of County in the aggregate
  summarise(Avg_Providers_25_3 = mean(Wired25_3_2020), 
            Avg_Providers_100_3 = mean(Wired100_3_2020),
            Avg_percent_access = mean(Percent_access),
            Avg_month_price = mean(Month_price),
            Medi_Mbps = median(AverageMbps),
            Medi_fast_Mbps = median(FastestAverageMbps),
            Rurality = mean(Rurality),
            Num_Household = mean(Household),
            Home_w_student = mean(Student),
            Has_PC = mean(Has.computer),
            Has_PC_Int = mean(Has.computer.and.broadband),
            Has_PC_only = mean(Has.computer.and.nointernet),
            No_PC = mean(No.computer))
```

```{r eval=FALSE, include=FALSE}
#Broadband Now released data on github
broadbandurl <- 'https://raw.githubusercontent.com/BroadbandNow/Open-Data/master/broadband_data_opendatachallenge.csv'
broadbandnow <-read.csv(url(broadbandurl), header = T, sep = ",", strip.white = TRUE)

head(broadbandnow)
```

# Merge the final set of data

```{r}
data <-left_join(sch_broadband, a, by = "COUNTY.ID")
#There are 3138 rows with 33 variables 
```

```{r}
#Check for incomplete cases 
data[!complete.cases(data),] 
#There are 38 rows with incomplete data 
```

```{r}
#This tells me which columns have how many missing values. 
sapply(data, function(x) sum(is.na(x)))
#The 6 counties in VA that don't have FCC information also didn't map to this broadband now dataframe
```

```{r}
#Convert COUNTY.ID to factors level 
```

```{r eval=FALSE, include=FALSE}
#Export the dataframe for record
#write.csv(data,"D:/Documents/R/Digital Divide/Open_Data_Challenge/Analysis/data.csv")
```

\#------------------------------------------------------------------------------- \# Part 5. Statistical Analysis \#\# 5.1 Descriptive Statistics

```{r}
summary(data)
```

## Data Transformation for Household with Children on internet and computer info

```{r}
#Transform estimated counts to percentages
#The computer and internet data from Census are nested 
#Household with under 18 years old split by has computer or no computer.
#Within has computer(Has_PC), it is further divided into dial-up (excluded here), with internet(Has_PC_Int), and without internet(Has_PC_only)

#Percentage of PC ownership by household with student
data$Percent_PC_H <- data$Has_PC/data$Home_w_student
data$Percent_Int_PC <- data$Has_PC_Int/data$Has_PC
```

### Most Populated regions with K-12 students enrollment

### Percenage of homes with K-12 students and their access to internet + SEDA

## Append an estimated final cost column to the broadband dataset for each county

### est_final_price

[The Cost of Connectivity Report](https://www.newamerica.org/oti/reports/cost-connectivity-2020/)suggests an average basic monthly cost of \$68.36 for the cities, with \$62.17 for promotional pricing and \$83.41 regular pricing. Check the range of prices from the broadband dataset.

[The Cost of Connectivity Report for Rural Area](https://www.google.com/url?q=https://www.newamerica.org/oti/reports/cost-connectivity-2020/&sa=D&source=editors&ust=1616209955787000&usg=AFQjCNHFDSBxivsvU44hETbKRpeyPneifw) (page 9) Average download speed in WV rural area is 25.65 Mbps, avg upload is 3.39 Mbps. (page 6) reported cost is advertised costs for new customer that would pay but not the actual price. (page 7) Median monthly cost is \$84.99 for non-promotional pricing without equipment rental, speed surcharge, modem, and other fees.

## 5.2 Correlation Analysis

```{r}
#Subset the data for correlational analysis 
data_1 <- data[, c("City", "Suburb", "Town", "Rural", "Rurality",
                   "Percent_access_FCC", "Percent_usage",
                   "Avg_percent_access", "Medi_Mbps",
                   "Medi_fast_Mbps", "Percent_PC_H", "Percent_Int_PC")]
```

### Urbanicity/Rurality with Broadband Access and Usage

```{r}
#Plot to see a scatter plot
plot(data_1$City, data_1$Avg_percent_access)
plot(data_1$Percent_access_FCC, data_1$Percent_usage)
```

```{r}
cor(data_1, use = "complete.obs", method = c("pearson"))
```

```{r}
library(corrplot)
```

```{r}
cortable <- cor(data_1, use = "complete.obs", method = c("pearson"))
corrplot(cortable, method = "number", type = "upper", number.cex = 0.7, tl.cex = 0.7)
```

```{r}
cor(data_1, use = "complete.obs", method = c("spearman"))
```

```{r}
cortable2 <- cor(data_1, use = "complete.obs", method = c("spearman"))
corrplot(cortable2, method = "color", addCoef.col="grey", type = "upper", number.cex = 0.7, tl.cex = 0.7) 
```

### No. of schools, Titile 1 status in the region and FCC availability

```{r}
data_2 <- data[, c("COUNTY.ID", "Num_of_school","Total_enrollment", "City", 
               "Suburb", "Town", "Rural", "Rurality", "TAE_No", "TAE", "SW_TAE",
               "SW_No", "SW", "NOT_TitleI", "Unknown", "Percent_access_FCC",
               "Percent_usage", "Avg_percent_access", "Medi_Mbps", 
               "Medi_fast_Mbps", "Percent_PC_H", "Percent_Int_PC")]
```

For Title I status, there are different categories. [Title I allocation at the federal level](https://nces.ed.gov/blogs/nces/post/a-look-at-how-title-i-funds-are-allocated-in-the-u-s)

```{r}
#For this part of the analysis, we aggregate the title 1 status into one variable.
data_2 <- transform(data_2, Title_I = (1 - NOT_TitleI))
```

```{r}
#Remove the un-needed columns in data_2
colnames(data_2)

data_3 = subset(data_2, select = -c(9:13, 15))
```

```{r}
colnames(data_3)
```

```{r eval=FALSE, include=FALSE}
cortable3 <- cor(data_3, use = "complete.obs", method = c("spearman"))
corrplot(cortable3, method = "color", addCoef.col="grey", type = "upper", number.cex = 0.7, tl.cex = 0.7) 
```

Format tabular data with formattable package (p.28 R Statistics Book)

```{r}
library(expss)
library(formattable)
```

[Data Viz Color Scheme](https://www.datanovia.com/en/blog/top-r-color-palettes-to-know-for-great-data-visualization/)

```{r}
library(RColorBrewer)
display.brewer.all()
```

```{r}
#t5 <- with(data_3, table(COUNTY.ID, Percent_usage))
#this method spreads out the count of each percent_usage for each county. 
t5 <- select(data_3, COUNTY.ID, Title_I, Rurality, Percent_usage, Medi_Mbps, Percent_PC_H, Percent_Int_PC)
t5
```

```{r}
#Rounding values to 2 decimal places
t5<- round(t5, digits = 2)
```

```{r}
#Setup color first 
col1 <- brewer.pal(n = 5, name = "Reds" ) #Sequential color 
display.brewer.pal(n = 5, name = "Reds")

#apply formatting 
formattable(t5, align = c("l", rep("r", NCOL(t5)-1,
                                    list("Title_I" = color_bar(col1)))))
              
#https://www.displayr.com/formattable/        
```

```{r}
cor(t5, use = "complete.obs")
#Correlation reflects the increase in percentage of title 1 schools within a county, their usage and speed is inverse. 
```

### No. of computer and internet access at household by SEDA scores

SEDA scores are divided by grade and subject. Therefore, the

## Load SEDA dataset

### SEDA scores by county, grade, subject

```{r}
seda_score <-read.csv("seda_scores.csv", header = T)
```

```{r}
colnames(seda_score)
```

fips: State FIPS code sedacounty: FIPS County Code cs_mn_all: County grade-year-subject (gyb) Ach Mean, All Students, Cohort Scale (CS) cs_mn_all: County grade-year-subject (gyb) Standard Error (SE) of Ach Mean, All Students, Cohort Scale (CS) totgyb_all: Sample size of all estimates (number of tests in grade-year-subject)

```{r}
head(seda_score)
```

Note: Estimates in this scale are comparable across the whole country and over time, but not across grades or subjects. See the technical documentation, and Reardon, Kalogrides, and Ho (2019), for details.

Note. CS version of the SEDA data is for research purposes, in which one unit in SD in student proficienty level in each grade referenced to NAEP average.

```{r}
#Kernel Density Plot of Math, 3rd grade 

a <- density(seda_score$cs_mn_all, na.rm = T, kernel = c("gaussian"))
plot(a, main = "Density plot of all scores in cs_mn_all")
```

#### Subset data as "b" in tibble

```{r}
#take the needed columns 
b <- seda_score %>%
  group_by(sedacounty, subject, grade) %>%
  summarise(score = sum(cs_mn_all))
b
  
```

#### Spread the tibble

```{r}
#Spread the data by grade level to subjects 
b_wide <- b %>% 
  spread(subject, score)
b_wide
```

<https://datascienceplus.com/converting-data-from-long-to-wide-and-from-wide-to-long-simplified-tidyverse-package/>

### Covariates

```{r}
seda_cov <-read.csv("seda_covariates.csv", header = T)
```

```{r}
colnames(seda_cov)
```

```{r}
head(seda_cov)
```

#### Subset columns

sedacounty: SEDA County ID (2018) grade: grade level from 3-8 perind: percent native americans in the grade perasn: percent asians in the grade perhsp: percent hispanics in the grade perblk: percent blacks in the grade perwht: percent whites in the grade perfl: percent free lunch in the grade perrl: percent reduced lunch in the grade perfrl: percent free or reduced lunch in the grade perecd: percent economically disadvantaged in the grade perell: % of all Students in County that are ELL (not available) perspeced: % of all Students in County that are Special Ed (not available) hsflnfl: the information theory index is computed as the average deviation of each student's school racial diversity from the district-wide racial diversity. Values of 0 indicate no segregation while values of 1 indicate complete segregation. See Theil (1972) for more hsecdnec:the information theory index is computed as the average deviation of each student's school racial diversity from the district-wide racial diversity. Values of 0 indicate no segregation while values of 1 indicate complete segregation. See Theil (1972) for more sesall: ses composite, eb estimate, all families, time-varying

Note: % schools in county that are located in urban, suburban, town, and rural are already in the school dataset.

```{r}
cov <- select(seda_cov, c("sedacounty","grade","perind","perasn","perhsp",
                          "perblk","perwht","perfl","perrl","perfrl","perecd",
                          "hsflnfl","hsecdnec","sesall"))
```

```{r}
colnames(cov)
```

```{r}
head(cov)
```

### Combine scores and covariates dataframe

```{r}
seda_combo <- left_join(b_wide, cov, by = c("sedacounty", "grade"))
```

```{r}
anti_join(b_wide, cov, by = "sedacounty")
#The county ID 46102 was not present in the seda covariate dataset 
```

## 5.3 Regression Analysis

### Access level Composite Indicator

We conceptualize access level for K-12 students in the context of physical access (which includes internet access and technology in a form of PC).

First level of digital divide - Internet connection (van Deursen & van Dijk, 2019) - subcomponents of first level is material access in which beside internet connection, there are computer devices, software subscription, and peripheral equipment. Material access can be distinguished as device opportunity (substitution between PC, smartphone or tablet), device and peripheral diversity (number of devices), and maintenance expenses (level of subscription and cost).

Second level of digital divide - Internet skills and usage Third level of digital divide - Tangible benefits of internet use

```{r}
#Load the Dataframe of School information first 
head(data)
```

```{r}
colnames(data)
```

#### Missing Values

```{r}
data[!complete.cases(data),] 
```

```{r}
#Drop unnecessary columns 
data <- data[-c(19, 27, 30:33)]
```

```{r}
data[!complete.cases(data),] 
```

These are the counties being imputed 82 2158 Kusilvak Census Area 2410 46102 Oglala Lakota County 2918 51580 Covington city 2920 51595 Emporia city 2921 51600 Fairfax city 2929 51678 Lexington city 2932 51685 Manassas Park city 2933 51690 Martinsville city

#### Imputation

```{r}
#Address missing values
library(GGally)
library(missRanger)
```

```{r}
data_imputed <-missRanger(data, num.trees = 1000)
```

```{r}
#Export the dataframe for record
#write.csv(data_imputed,"D:/Documents/R/Digital Divide/Open_Data_Challenge/Analysis/data_imputed.csv")
```

### PCA

<https://www.kaggle.com/agailloty/comprehensive-pca-with-r-using-factominer>

```{r}
library(FactoMineR)
```

```{r}
colnames(data_imputed)
```

```{r}
# Store the PCA result in an object valled data_pca
# quali.sup is to choose variables that gives context in the data and not meant for PCA 
data_pca <- PCA(data_imputed, quali.sup = c(1, 2, 18), graph = T)
```

```{r}
summary(data_pca)
```

```{r}
data_pca$eig
```

```{r}
#Plot the variable factor map
plot.PCA(data_pca, axes = c(1,2), choix = "var") +
  theme(panel.grid.major = element_blank(),
        plot.title =element_text(size=14, color="blue"),
        axis.title = element_text(size=12, color="red")) 
#Dim 1 is correlation by Pearson r

```

```{r}
data_pca$var
```

```{r}
#Contribution of each variable on the dimensions
data_pca$var$contrib
```

```{r}
library(factoextra)
```

<http://www.sthda.com/english/articles/31-principal-component-methods-in-r-practical-guide/118-principal-component-analysis-in-r-prcomp-vs-princomp/>

```{r}
fviz_screeplot(data_pca, addlabels = TRUE, ylim = c(0, 50))
```

```{r}
fviz_pca_ind(data_pca,
             col.ind = "cos2", # Color by the quality of representation
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE     # Avoid text overlapping
             )
```

```{r}
# Extract the results for variables
var <- get_pca_var(data_pca)
```

```{r}
# Contributions of variables to PC1
fviz_contrib(data_pca, choice = "var", axes = 1, top = 10)
```

```{r}
# Contributions of variables to PC2
fviz_contrib(data_pca, choice = "var", axes = 2, top = 10)
```

```{r}
# Control variable colors using their contributions to the principle axis
fviz_pca_var(data_pca, col.var="contrib",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE # Avoid text overlapping
) + theme_minimal() + ggtitle("Variables - PCA")
```

Purdue Digital Divide Index <https://storymaps.arcgis.com/stories/8ad45c48ba5c43d8ad36240ff0ea0dc7>

The INFA score groups five variables related to broadband infrastructure and adoption: (1) percentage of total 2018 population without access to fixed broadband of at least 100 Mbps download and 20 Mbps upload as of December 2019; (2) percent of homes without a computing device (desktops, laptops, smartphones, tablets, etc.); (3) percent of homes with no internet access (have no internet subscription, including cellular data plans or dial-up); (4) median maximum advertised download speeds; and (5) median maximum advertised upload speeds.

The SE score groups five variables known to impact technology adoption: (1) percent population ages 65 and over; (2) percent population 25 and over with less than high school; (3) individual poverty rate; (4) percent of noninstitutionalized civilian population with a disability: and (5) a brand new digital inequality or internet income ratio measure (IIR). In other words, these variables indirectly measure adoption since they are potential predictors of lagging technology adoption or reinforcing existing inequalities that also affect adoption.

Because these variables have different units and normal distributions, z-scores were calculated for each variable and geography. Z-scores standardize the data and indicate where a particular observation falls compared to the mean and standard deviation of the sample. Please note that these scores were calculated by looking at the geographic units (Census tracts, counties) and comparing them with their peers. For this reason, scores are not comparable across different geography tiers (Census tract versus counties versus states).

ince the DDI was designed to show a larger digital divide as the score increases, careful attention was paid to the signs in equations 1 and 2. The rationale behind the infrastructure/adoption (INFA) score (equation 1) was: as the z-scores of the percent of population without fixed 100/20 (NBBND), no internet access (NIA), and no computing devices (NCD) increases (+), the divide increases; while the z-scores of the median download (DNS) and upload (UPS) speeds increase, the digital divide decreases (-).

A similar rationale was used to calculate the socioeconomic score (SE) in equation 2: as the z-scores of the percent population ages 65 and over (AGE65) increases (+), so does the potential lag in technology adoption; same as the z-scores of individual poverty rate (POV) increases (+), percent population 25 and over without a high school degree (LTHS) increases (+), and percent noninstutionalized population with any disability (DIS) increases (+), so does the digital divide.

Equation 1: INFA = NBBND*0.3 + NIA*0.3 + NCD*0.3 -- DNS*0.05 -- UPS\*0.05 Equation 2: SE = AGE65 + POV + LTHS + DIS

Notice however that the SE components are given equal weight while INFA components are not. This may result in more variance in the SE score compared to the INFA score. This in turn gives SE more influence on the DDI score compared to the INFA score. For this reason, z-scores of the INFA and SE scores were calculated and then added up to calculate the final DDI score giving both components equal influence as shown in equation 3.

Equation 3: DDI = INFA + SE

#### Percent usage for household with children

```{r}
#Rename the dataset
imp_data <- data_imputed
```

```{r}
#Percent of family that have children within each county
imp_data$Percent_Fm <- imp_data$Home_w_student/imp_data$Num_Household
```

```{r}
#Percent of usage is from household with children
imp_data$Percent_stu_usage <- imp_data$Percent_usage*imp_data$Percent_Fm
```

##### Access level is made up of % computer and internet at home per household (as a physical acess) + quality of broadband (infrastructure, 25/3 Mbps, lowest fixed broadband in DDI) + Opportunity (by provider) and then compare to Actual Usage (by Microsoft)

##### Adding demographic information to this measure and then do a group comparison on this measure to detemine access by group. Then we can also use the access level in comparison with relative diversity index to see if there is any correlation.

## Multilevel Modeling

How does broadband access and use varies across schools with different Title 1 status?

## Spatial Analysis
